---
date: "`r Sys.Date()`"
output:
  html_document: default
---

# Week 1 Practice 
Let's just practice around in R to get a feel for how R performs its operations. 

We'll end the session by pushing our final script to the GitHub repository you made in class. (Or if you didn't make one, make one now for this class :]). 

First, we'll download this data from a `tidytuesday` post. In the spirit of dealing with some data that has to do with political issues, let's take a look at [this data](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-22) from the Vera Institute about incarceration trends. I've chosen the `incarceration_trends.csv`, which is the full raw data provided on the post. 

We'll load in the data and then also remember to go ahead and load the packages that you think you will need to do your data exploration. For now, `tidyverse` is probably sufficient. 

```{r, include=T, eval= T}
incarceration <- read.csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-22/incarceration_trends.csv")

library(tidyverse)

```

## Exploring the Data   

Before you can do really anything with the data, you will want to check for a codebook or any equivalent documentation of the properties of the data. 

The entire codebook is really quite long (43 pages!), which is great because that means the data is well documented. This is the best case scenario for visualization and analysis. I will save myself from just rehashing the entire codebook here, and suggest that if you want to play with this dataset beyond what I provide here, then please visit the [site link.](https://github.com/vera-institute/incarceration_trends/blob/master/incarceration_trends-Codebook.pdf?raw=true) 

If you'll notice, the dataset that I have chosen here is in ``raw" format. What does that mean? It means that the data is in its collected format, there are no summaries that have been conducted, and the data in this case is **wide**. What is wide data? Well we can take a look at the data to find out more. 

To begin with, I always suggest looking at your data in two ways, depending on your level of familiarity with the data to begin with. The first is with the `glimpse()` function from `dplyr`-- a package you loaded in with the `tidyverse`. The only **argument** that goes into `glimpse()` for now is our dataset name. 

In the instance that you are already acquainted with your data, that is you already know the variables in there and the general structure and just want to be reminded of the dimensions of your data, you can instead run the function `dim()`. This command also takes just the dataset name as the argument. 

```{r, eval = T}
# option 1 

glimpse(incarceration)

#147,533 obs over 79 vairables 

# option 2 

dim(incarceration)

```
In the case of the `glimpse()` function,  you will see that this gives us so much more information that it's almost worthwhile to do it regardless of whether we already know the data or not. This is also useful and will be useful for the visualization perspective in that we see *how* certain variables are stored. Our options for visualizing the `year` variable look much different when R treats this as a integer value as opposed to a numeric value. Equivalently, seeing the types of data on their own will lead to intuitive choices for the *appropriate* type of graph in certain instances. For example, the variable named `urbanicity` in this dataset is coded as a character variable with the values `small/mid`, `rural`, `suburban`, or `urban`. Our choices to visualize the data for this variable look much different than if the urbanicity were scored on a numeric scale from 0 to 100. 

Let's continue to explore. 

Remember that when we are dealing in base R, if we want R to index a certain variable in a dataset that we use the dollar sign ($) operator appended to the dataset name. For example, if I wanted to see the unique values of the variable `urbanicity` (as we did above, I would run the following command). 

```{r, eval=F}
unique(incarceration$urbanicity)

# the returned result are the unique values of the urbanicity variable 

# maybe we just want to see all of the names of the variables

names(incarceration)

```

One important facet of data to always explore is the presence of NA values. These are missing observations. In case of survey data, this could mean non-response. In other cases, it might mean the value can't be found for that particular case. In other cases, it might indicate that a value really is not applicable for that case at that particular observation point. We can work throughout the quarter to discern when misisng values are a problem. 

For now we will see what methods we have for checking for NAs. Let's check for this on the variable `total_jail_adm`, whcih is the total jail admissions count. 

```{r, echo=T, eval= F}
is.na(incarceration$total_jail_adm)
#gives us a bunch of logical values as to whether the observation is an NA or not.... not so useful

#instead we can see how many NA values are in this variable 

sum(is.na(incarceration$total_jail_adm))
#6,300 missing values 

# we can also perform arithmetic on these functions
# for example what percentage of our total observations are NA on this variable?
# we can do this two ways, 1) divide by the raw number of total observations (147,533)
# 2) index the number of observations given the dim() function 

# option 1 
# missing values in the variable / total number of observations in data 
sum(is.na(incarceration$total_jail_adm))/ 147533 #0.043 

# option 2 
# missing values in the variable / dim(incarceration)[1], this just indexes the same number as option 1
sum(is.na(incarceration$total_jail_adm))/ dim(incarceration)[1] #0.043 

# result is the same! 
```


## Saving things as objects

We talked in class how R is an object-oriented coding language. We also created a couple of different objects.

There are a couple of different objects that we can create, atomic vectors, lists, matrices, dataframes. We will really only focus on the vectors and dataframes. 

We can also easily create a bunch of one type of object and combine then into another object type. To do so, we'll just come up with some toy data.  

```{r, eval=T}
# the "c" is for concatenate or combine! 
# it just means we want all of the stuff from that parentheses to be included in the defined object

# let's just throw some countries together 
country <- c("USA", "Mexico", "Afghanistan", "Thailand")

# and their respective continents
continent <- c("North America", "North America", "Asia", "Asia")

# and some information on their geographical location 
equator <- c(0, 1, 0, 1) # whether the country is above the equator (0), at the equator/between the tropics (1), below the equator (2)

# combine together with the command data.frame() and each of the variable names 
country_df <- data.frame(country, continent, equator)

country_df
```
Note that the order of the information in the variables is important. If you want to merge together data, you need to make sure that the data is ordered in a way that makes sense *or* that you have a key variable to merge on. We will explore this more next week. 

We might also want to create objects to store output information from certain summary operations. And later on-- plots! You can save anything as an object in R, as long as you use that `<-` assignment operator. 

As an example, we'll return to the incarceration data variable `incarceration$total_jail_adm` from above: 

```{r, eval=T}
# can either just run the command 
mean(incarceration$total_jail_adm, na.rm = T)

# or can store the output as an object 
mean_jail_adm <- mean(incarceration$total_jail_adm, na.rm = T)
mean_jail_adm
```

## Pushing the script and the incarceration file to R 

We can also save stuff from R onto our computer. Let's save the dataset that you loaded in. Remember that it came from the internet, so we don't actually have a copy on our computer. 

First, set your working directory to the local version of your GitHub file. Then, save the incarceration data to the working directory. Last, we'll push the uploaded file to the GitHub remote repository using GitHub Desktop (you'll need to make sure this file is being watched by GitHub Desktop, if you have a question about this email me!). 

```{r, eval=F}
# 1) check working directory  

getwd()

# 2) set the working directory 

setwd("/Users/sarahmoore/Desktop/data_viz_390/")

# 3) save the incarceration data as a csv to the file 

write.csv(incarceration, "incarceration_trends.csv")

# 4) check the data is in the file specified 

# 5) push to the associated GitHub 
```

![Follow these steps](/Users/sarahmoore/OneDrive - Northwestern University/Teaching/2022_Fall_DataViz/lousy-graphs/exercises/github_screenshot.png)

But committing the file does not actually send the file to the remote repository. So then we have to push the commit. 


![Push!](/Users/sarahmoore/OneDrive - Northwestern University/Teaching/2022_Fall_DataViz/lousy-graphs/exercises/github_push.png)